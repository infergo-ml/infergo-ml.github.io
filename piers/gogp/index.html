<!DOCTYPE html>
<html class="nojs" lang="en" dir="ltr">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=2.0, user-scalable=yes">
<title>GoGP – Infergo — Go programs that learn</title>
<meta name="created" content="0001-01-01T00:00:00&#43;0000">
<meta name="modified" content="0001-01-01T00:00:00&#43;0000">
<meta name="author" content="David Tolpin">
<meta name="description" content="GoGP is a library for probabilistic programming around Gaussian processes. It uses Infergo for automatic differentiation and turning Gaussian processes as probabilistic models. GoGP is built around a dual view on the Gaussian process  as a stochastic process, as a probabilistic model with respect to kernel.  Gaussian process instance GP, the Gaussian process type, encapsulates similarity and noise kernels, their parameters, and observation inputs and outputs: // Type GP is the barebone implementation of GP.">
<meta property="og:site_name" content="Infergo — Go programs that learn">
<meta property="og:title" content="GoGP">
<meta property="og:url" content="http://infergo.org/piers/gogp/">

<meta name="generator" content="Hugo 0.53-DEV" />

<link rel="canonical" href="http://infergo.org/piers/gogp/">
<link rel="icon" href="/favicon.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="stylesheet" href="/css/styles.css">
<link rel="stylesheet" href="/css/print.css" media="print">
<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "\"GoGP\"",
    "datePublished": "0001-01-01T00:00:00Z",
    "dateModified": "0001-01-01T00:00:00Z",
    "url" : "http:\/\/infergo.org\/piers\/gogp\/",
    "description": "\"GoGP is a library for probabilistic programming around Gaussian processes. It uses Infergo for automatic differentiation and turning Gaussian processes as probabilistic models. GoGP is built around a dual view on the Gaussian process  as a stochastic process, as a probabilistic model with respect to kernel.  Gaussian process instance GP, the Gaussian process type, encapsulates similarity and noise kernels, their parameters, and observation inputs and outputs: // Type GP is the barebone implementation of GP.\"",
    "author": {
      "@type": "Person",
      "name": "\"David Tolpin\""
    },
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/infergo.org\/"
    },
    "publisher": {
      "@type": "Organization",
      "name": "\"Infergo — Go programs that learn\"",
      "url": "http:\/\/infergo.org\/",
    }
  }
</script>

</head>

<body>
<div class="page layout__page layout__sidebar-second">
<header class="header layout__header" role="banner">
<h1 class="header__site-name">
<a href="/" title="Home" rel="home" class="header__logo"><img src="/images/logo.png" alt="Home" class="header__logo-image"></a>
<a href="/" title="Home" class="header__site-link" rel="home"><span>Infergo — Go programs that learn</span></a>
</h1>
<div class="region header__region">


</div>
</header>




<nav class="main-menu layout__navigation" role="navigation">
<h2 class="visually-hidden">Main menu</h2>
<ul class="navbar">
<li><a class="" href="/">Home</a></li>
<li><a class="" href="/start/">Getting started</a></li>
<li><a class="" href="/guide/">Guide</a></li>
<li><a class="" href="/examples/">Examples</a></li>
<li><a class="" href="/team/">Team</a></li>
<li><a class="active" href="/piers/">Piers</a></li>
<li><a class="" href="/news/">News</a></li>
</ul>
</nav>


<main class="main layout__main" role="main">
<h1 class="title ">GoGP</h1>
<article class="section-piers single-view">
<header>
</header>
<div class="content">


<p><a href="http://bitbucket.org/dtolpin/gogp">GoGP</a> is a
library for probabilistic programming around Gaussian processes.
It uses <a href="http://infergo.org/">Infergo</a> for automatic
differentiation and turning Gaussian processes as probabilistic
models.</p>

<p>GoGP is built around a dual view on the Gaussian process</p>

<ul>
<li>as a stochastic process,</li>
<li>as a probabilistic model with respect to kernel.</li>
</ul>

<h2 id="gaussian-process-instance">Gaussian process instance</h2>

<p><code>GP</code>, the Gaussian process type, encapsulates similarity
and noise kernels, their parameters, and observation inputs
and outputs:</p>

<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#60a0b0;font-style:italic">// Type GP is the barebone implementation of GP.
</span><span style="color:#60a0b0;font-style:italic"></span><span style="color:#007020;font-weight:bold">type</span> GP <span style="color:#007020;font-weight:bold">struct</span> {
	NDim                   <span style="color:#902000">int</span>       <span style="color:#60a0b0;font-style:italic">// number of dimensions
</span><span style="color:#60a0b0;font-style:italic"></span>	Simil, Noise           Kernel    <span style="color:#60a0b0;font-style:italic">// kernels
</span><span style="color:#60a0b0;font-style:italic"></span>	ThetaSimil, ThetaNoise []<span style="color:#902000">float64</span> <span style="color:#60a0b0;font-style:italic">// kernel parameters
</span><span style="color:#60a0b0;font-style:italic"></span>
	X [][]<span style="color:#902000">float64</span> <span style="color:#60a0b0;font-style:italic">// inputs
</span><span style="color:#60a0b0;font-style:italic"></span>	Y []<span style="color:#902000">float64</span>   <span style="color:#60a0b0;font-style:italic">// outputs
</span><span style="color:#60a0b0;font-style:italic"></span>}</code></pre></div>

<p>Public methods defined on GP fall into two groups: Gaussian
process fitting and prediction, on one hand, and
probabilistic model interface, on the other hand.</p>

<h3 id="gaussian-process-methods">Gaussian process methods</h3>

<p><code>Absorb</code> updates the GP with observations, <code>Produce</code> returns
predicted outputs for unseen inputs.</p>

<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">func</span> (<span style="color:#666">*</span>GP) <span style="color:#06287e">Absorb</span>(x [][]<span style="color:#902000">float64</span>, y []<span style="color:#902000">float64</span>)
<span style="color:#007020;font-weight:bold">func</span> (<span style="color:#666">*</span>GP) <span style="color:#06287e">Produce</span>(x [][]<span style="color:#902000">float64</span>) (mu, sigma []<span style="color:#902000">float64</span>)</code></pre></div>

<p>When kernel parameters are fixed (known or learned), <code>Absorb</code>
and <code>Produce</code> are all that is needed for posterior GP inference.</p>

<h3 id="probabilistic-model-methods">Probabilistic model methods</h3>

<p><code>Observe</code> and <code>Gradient</code> turn a GP instance into an elemental
Infergo model (that is, a model with supplied gradient). The
model can be passed to inference algorithms or used within
another model.</p>

<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">func</span> (<span style="color:#666">*</span>GP) <span style="color:#06287e">Observe</span>(x []<span style="color:#902000">float64</span>) <span style="color:#902000">float64</span>
<span style="color:#007020;font-weight:bold">func</span> (<span style="color:#666">*</span>GP) <span style="color:#06287e">Gradient</span>() []<span style="color:#902000">float64</span> <span style="color:#666">//</span> <span style="">`</span>elemental<span style="">&#39;</span> model</code></pre></div>

<p>If the length of <code>x</code> is equal to the number of kernel hyperparameters
(<code>Simil.NTheta() + Noise.NTheta()</code>) then the gradient of
marginal likelihood  is computed with respect to kernel
hyperparameters only. Observations must be provided in the fields
of the GP instance. Otherwise, if the length of <code>x</code> is greater
than the number of parameters, the rest of <code>x</code> is interpreted
as observations. In the latter case, the gradient is computed
with respect to both kernel hyperparameters and observations.</p>

<h2 id="kernels">Kernels</h2>

<p>There are two kernel kinds:</p>

<ul>
<li>similarity kernel;</li>
<li>noise kernel.</li>
</ul>

<p>Both kinds must satisfy the Kernel interface:</p>

<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">type</span> Kernel <span style="color:#007020;font-weight:bold">interface</span> {
	<span style="color:#06287e">Observe</span>([]<span style="color:#902000">float64</span>) <span style="color:#902000">float64</span>
	<span style="color:#06287e">NTheta</span>() <span style="color:#902000">int</span>
}</code></pre></div>

<p>The <code>Observe</code> method computes the variance or covariance,
the <code>NTheta</code> method returns the number of kernel parameters.</p>

<p>A similarity (or covariance) kernel receives concanetation
of kernel parameters and coordinates of two points. A noise
kernel receives concatenation of kernel parameters and
coordinates of a single point. Here is an example implementation
of the RBF (or normal) kernel:</p>

<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">type</span> RBF <span style="color:#007020;font-weight:bold">struct</span>{}

<span style="color:#007020;font-weight:bold">func</span> (RBF) <span style="color:#06287e">Observe</span>(x []<span style="color:#902000">float64</span>) <span style="color:#902000">float64</span> {
	l, xa, xb <span style="color:#666">:=</span> x[<span style="color:#40a070">0</span>], x[<span style="color:#40a070">1</span>], x[<span style="color:#40a070">2</span>]
	d <span style="color:#666">:=</span> (xa <span style="color:#666">-</span> xb) <span style="color:#666">/</span> l
	<span style="color:#007020;font-weight:bold">return</span> math.<span style="color:#06287e">Exp</span>(<span style="color:#666">-</span>d <span style="color:#666">*</span> d <span style="color:#666">/</span> <span style="color:#40a070">2</span>)
}

<span style="color:#007020;font-weight:bold">func</span> (RBF) <span style="color:#06287e">NTheta</span>() <span style="color:#902000">int</span> { <span style="color:#007020;font-weight:bold">return</span> <span style="color:#40a070">1</span> }</code></pre></div>

<h2 id="case-studies">Case studies</h2>

<p>GoGP includes case
<a href="http://bitbucket.org/tolpin/gogp/src/master/tutorial">studies</a>,
illustrating, on simple examples, common patterns of GoGP use.
We briefly summarize here some of the case studies.</p>

<h3 id="basic-usage">Basic usage</h3>

<p>In the basic case, similar to that supported by many Gaussian
process libraries, a GP directly serves as the model for
inference on hyperparameters (or the hyperparameters can be just
fixed).</p>

<p>The library user specifies the kernel:</p>

<p><div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">type</span> Basic <span style="color:#007020;font-weight:bold">struct</span>{}
<span style="color:#007020;font-weight:bold">func</span> (Basic) <span style="color:#06287e">Observe</span>(x []<span style="color:#902000">float64</span>) <span style="color:#902000">float64</span> {
    <span style="color:#007020;font-weight:bold">return</span> x[<span style="color:#40a070">0</span>] <span style="color:#666">*</span> kernel.Normal.<span style="color:#06287e">Observe</span>(x[<span style="color:#40a070">1</span>:])
}
<span style="color:#007020;font-weight:bold">func</span> (Basic) <span style="color:#06287e">NTheta</span>() <span style="color:#902000">int</span> { <span style="color:#007020;font-weight:bold">return</span> <span style="color:#40a070">2</span> }</code></pre></div>
and initializes <code>GP</code> with a kernel instance:
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">gp <span style="color:#666">:=</span> <span style="color:#666">&amp;</span>gp.GP{
    NDim:  <span style="color:#40a070">1</span>,
    Simil: Basic{},
}</code></pre></div></p>

<p>MLE inference on hyperparameters and prediction can then be performed
through library functions.</p>

<h3 id="priors-on-hyperparameters">Priors on hyperparameters</h3>

<p>If priors on hyperparameters are to be specified, the library
user provides both the kernel and the model.  <code>GP</code> is
initialized with the kernel, and then <code>GP</code> and the
model are combined for inference in a derived model:
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">type</span> Model <span style="color:#007020;font-weight:bold">struct</span> {
    gp           <span style="color:#666">*</span>gp.GP
    priors       <span style="color:#666">*</span>Priors
    gGrad, pGrad []<span style="color:#902000">float64</span>
}
<span style="color:#007020;font-weight:bold">func</span> (m <span style="color:#666">*</span>Model) <span style="color:#06287e">Observe</span>(x []<span style="color:#902000">float64</span>) <span style="color:#902000">float64</span> {
    <span style="color:#007020;font-weight:bold">var</span> gll, pll <span style="color:#902000">float64</span>
    gll, m.gGrad =
      m.gp.<span style="color:#06287e">Observe</span>(x), model.<span style="color:#06287e">Gradient</span>(m.gp)
    pll, m.pGrad = 
      m.priors.<span style="color:#06287e">Observe</span>(x),model.<span style="color:#06287e">Gradient</span>(m.priors)
    <span style="color:#007020;font-weight:bold">return</span> gll <span style="color:#666">+</span> pll
}
<span style="color:#007020;font-weight:bold">func</span> (m <span style="color:#666">*</span>Model) <span style="color:#06287e">Gradient</span>() []<span style="color:#902000">float64</span> {
	<span style="color:#007020;font-weight:bold">for</span> i <span style="color:#666">:=</span> <span style="color:#007020;font-weight:bold">range</span> m.pGrad {
		m.gGrad[i] <span style="color:#666">+=</span> m.pGrad[i]
	}
	<span style="color:#007020;font-weight:bold">return</span> m.gGrad
}</code></pre></div>
In <code>Model</code>, <code>gp</code> holds a <code>GP</code>
instance and <code>priors</code> holds an instance of the model
expressing beliefs about hyperparameters. A <code>Model</code>
instance is used for inference on hyperparameters, a
<code>GP</code> instance &mdash; for prediction.</p>

<h3 id="uncertain-observation-inputs">Uncertain observation inputs</h3>

<p>When observation inputs are uncertain, beliefs about inputs can
be specified, and the log-likelihood gradient can be computed
with respect to both hyperparameters and observation inputs. For
example, in a time series, one can assume that observation
inputs come from a renewal process and let the inputs move
relative to each other. Then, forecasting can be performed
relative to posterior observation inputs.</p>

<h3 id="non-gaussian-noise">Non-Gaussian noise</h3>

<p>In basic usage, the observation noise is assumed to be Gaussian.
This usage is supported by initializing <code>GP</code> with a noise
kernel, along with a similarity kernel. When the noise is not
Gaussian, an analytical solution for posterior Gaussian process
inference does not always exist. However, non-Gaussian noise is
straightforwardly supported by GoGP through supplying a
model for beliefs on observation outputs:
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#007020;font-weight:bold">type</span> Noise <span style="color:#007020;font-weight:bold">struct</span> {
	Y []<span style="color:#902000">float64</span> <span style="color:#60a0b0;font-style:italic">// noisy outputs
</span><span style="color:#60a0b0;font-style:italic"></span>}
<span style="color:#007020;font-weight:bold">func</span> (m <span style="color:#666">*</span>Noise) <span style="color:#06287e">Observe</span>(x []<span style="color:#902000">float64</span>) (ll <span style="color:#902000">float64</span>){
	<span style="color:#60a0b0;font-style:italic">// Laplacian noise
</span><span style="color:#60a0b0;font-style:italic"></span>	<span style="color:#007020;font-weight:bold">for</span> i <span style="color:#666">:=</span> <span style="color:#007020;font-weight:bold">range</span> m.Y {
		ll <span style="color:#666">+=</span> Expon.<span style="color:#06287e">Logp</span>(<span style="color:#40a070">1</span><span style="color:#666">/</span>math.<span style="color:#06287e">Exp</span>(x[<span style="color:#40a070">0</span>]),
			math.<span style="color:#06287e">Abs</span>(m.Y[i]<span style="color:#666">-</span>x[<span style="color:#40a070">1</span><span style="color:#666">+</span>i]))
	}
	<span style="color:#007020;font-weight:bold">return</span> ll
}</code></pre></div></p>


</div>
</article>
</main>



<aside class="sidebar layout__second-sidebar" role="complementary">
<section>
<h4 class="menu"><a class="" href="/piers/">Piers</a></h4>
<ul class="menu">
<li><a class="active" href="/piers/gogp/">GoGP</a></li>
</ul>
</section>
<section>
<h4 class="menu"><a class="" href="/news/">News</a></h4>
<ul class="menu">
<li><a class="" href="/news/v0.6.1/">infergo v0.6.1</a></li>
<li><a class="" href="/news/v0.5.0/">infergo v0.5.0</a></li>
<li><a class="" href="/news/tale-of-goids/">The Tale of GoIDs</a></li>
<li><a class="" href="/news/v0.3.0/">infergo v0.3.0</a></li>
<li><a class="" href="/news/v0.2.2/">infergo v0.2.2</a></li>
<li><a class="" href="/news/v0.2.1/">infergo v0.2.1</a></li>
<li><a class="" href="/news/why/">Why infergo</a></li>
</ul>
</section>
</aside>


<footer class="footer layout__footer" role="contentinfo">
<p><span>© Infergo — Go programs that learn</span></p>


</footer>

</div>



</body>
</html>
